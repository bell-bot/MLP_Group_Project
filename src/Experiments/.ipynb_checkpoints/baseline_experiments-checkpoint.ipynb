{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "848e39c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'constants'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_git_root\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mds\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/University/MLP/MLP_Group_Project/src/datasets.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_git_root\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpre_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resample_audio\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DATASET_TEDLIUM_PATH, DATASET_MLCOMMONS_PATH, LabelsCSVHeaders, LABELS_KEYPHRASES_CSV_PATH\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m############# --------- DATASETS --------------################\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#TODO! Customise for each subset, in speaker-adaptation. Might require changing the metadata\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTEDLIUMCustom\u001b[39;00m(tedlium\u001b[38;5;241m.\u001b[39mTEDLIUM):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'constants'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import L1Loss, MSELoss\n",
    "from enum import Enum\n",
    "\n",
    "from src.utils import get_git_root\n",
    "import src.datasets as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "109b978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify paths for labels and dataset\n",
    "data_paths = os.path.join(get_git_root(os.getcwd()), 'src' ,'Data')\n",
    "LABELS_KEYPHRASES_CSV_PATH = os.path.join(data_paths, \"Keyphrases\" , \"labels.csv\")\n",
    "TEDLIUM_WAV_PATH = os.path.join(data_paths, \"TEDLIUM_release-3\", \"data\", \"sph\")\n",
    "MSWC_WAV_PATH = os.path.join(data_paths, \"MSWCcc\", \"en\", \"clips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16c11d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the labels into a dataframe\n",
    "labels_df = pd.read_csv(LABELS_KEYPHRASES_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c23bb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>TEDLIUM_SampleID</th>\n",
       "      <th>TED_TALK_ID</th>\n",
       "      <th>TEDLIUM_SET</th>\n",
       "      <th>MSWC_AudioID</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Keyword, TEDLIUM_SampleID, TED_TALK_ID, TEDLIUM_SET, MSWC_AudioID, start_time, end_time, confidence]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df[labels_df[\"TEDLIUM_SET\"] == \"MarvinMinsky_2003\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4887005",
   "metadata": {},
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "730dc5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(audio): \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7403d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_split(frame_len, hop_len,data, print_frame = False):\n",
    "    frames = librosa.util.frame(data, frame_length=frame_len, hop_length=hop_len)\n",
    "    windowed_frames = np.hanning(frame_len).reshape(-1, 1) * frames\n",
    "    sum_len=0\n",
    "    if print_frame:\n",
    "        # Print frames\n",
    "        for i, frame in enumerate(frames):\n",
    "            print(\"Frame {}: {}\".format(i, frame))\n",
    "            print(\"Length of frame :{}\".format(len(frame)))\n",
    "            sum_len+=len(frame)\n",
    "        print(\"All frames :{}\".format(sum_len))\n",
    "        print(\"More data than original size: {}\".format(len(frames) <= sum_len))\n",
    "        # Print windowed frames\n",
    "        for i, frame in enumerate(windowed_frames):\n",
    "            print(\"Win Frame {}: {}\".format(i, np.round(frame, 3)))\n",
    "        \n",
    "    return frames,windowed_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2fa90f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_loss(x, y):\n",
    "    loss = L1Loss()\n",
    "    return torch.reshape(loss(x,y), shape=(1,1))\n",
    "\n",
    "def rmse_loss(x,y):\n",
    "    loss = MSELoss()\n",
    "    return torch.reshape(torch.sqrt(loss(x,y)), shape=(1,1))\n",
    "\n",
    "class LossType(Enum):\n",
    "    MAE = \"mae\"\n",
    "    RMSE = \"rmse\"\n",
    "\n",
    "\n",
    "def compare_window(keyword, window, loss_type=LossType.MAE):\n",
    "\n",
    "    if loss_type == LossType.MAE:\n",
    "        return mae_loss(keyword, window)\n",
    "\n",
    "    elif loss_type == LossType.RMSE:\n",
    "        return rmse_loss(keyword, window)\n",
    "\n",
    "def match_audio(keyword, sliding_windows, loss_type=LossType.MAE):\n",
    "    results = []\n",
    "    for i in range(len(sliding_windows)):\n",
    "        t = sliding_windows[i]\n",
    "        loss = compare_window(keyword, t, loss_type=loss_type)\n",
    "        results.append(loss)\n",
    "    return torch.cat(results, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab483c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>TEDLIUM_SampleID</th>\n",
       "      <th>TED_TALK_ID</th>\n",
       "      <th>TEDLIUM_SET</th>\n",
       "      <th>MSWC_AudioID</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>because</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>911Mothers_2010W</td>\n",
       "      <td>because/common_voice_en_97853.opus</td>\n",
       "      <td>15.031250</td>\n",
       "      <td>15.498812</td>\n",
       "      <td>0.934554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>911Mothers_2010W</td>\n",
       "      <td>the/common_voice_en_207024__2.opus</td>\n",
       "      <td>16.621125</td>\n",
       "      <td>16.741375</td>\n",
       "      <td>0.836357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fact</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>911Mothers_2010W</td>\n",
       "      <td>the/common_voice_en_207024__2.opus</td>\n",
       "      <td>16.821563</td>\n",
       "      <td>17.062062</td>\n",
       "      <td>0.998591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>911Mothers_2010W</td>\n",
       "      <td>the/common_voice_en_207024__2.opus</td>\n",
       "      <td>17.102187</td>\n",
       "      <td>17.242500</td>\n",
       "      <td>0.999760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>911Mothers_2010W</td>\n",
       "      <td>the/common_voice_en_207024__2.opus</td>\n",
       "      <td>17.523125</td>\n",
       "      <td>17.843813</td>\n",
       "      <td>0.944685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Keyword  TEDLIUM_SampleID TED_TALK_ID       TEDLIUM_SET  \\\n",
       "0  because                 0       train  911Mothers_2010W   \n",
       "1      the                 1       train  911Mothers_2010W   \n",
       "2     fact                 1       train  911Mothers_2010W   \n",
       "3     that                 1       train  911Mothers_2010W   \n",
       "4     have                 1       train  911Mothers_2010W   \n",
       "\n",
       "                         MSWC_AudioID  start_time   end_time  confidence  \n",
       "0  because/common_voice_en_97853.opus   15.031250  15.498812    0.934554  \n",
       "1  the/common_voice_en_207024__2.opus   16.621125  16.741375    0.836357  \n",
       "2  the/common_voice_en_207024__2.opus   16.821563  17.062062    0.998591  \n",
       "3  the/common_voice_en_207024__2.opus   17.102187  17.242500    0.999760  \n",
       "4  the/common_voice_en_207024__2.opus   17.523125  17.843813    0.944685  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419c838",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a2a520b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.7778121e-06 -8.6522118e-07 -5.0232247e-06 ... -6.1102759e-07\n",
      "  1.3981060e-06  0.0000000e+00]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.90 TiB for an array with shape (22050, 24292320) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m mfcc_keyword_audio \u001b[38;5;241m=\u001b[39m features_extractor(keyword_audio)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Window the tedlium input data \u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m frames, window_frames \u001b[38;5;241m=\u001b[39m \u001b[43mwindow_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyword_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m mfcc_audio \u001b[38;5;241m=\u001b[39m features_extractor(window_frames)\n\u001b[1;32m     37\u001b[0m start_time \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mwindow_split\u001b[0;34m(frame_len, hop_len, data, print_frame)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwindow_split\u001b[39m(frame_len, hop_len,data, print_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     frames \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mframe(data, frame_length\u001b[38;5;241m=\u001b[39mframe_len, hop_length\u001b[38;5;241m=\u001b[39mhop_len)\n\u001b[0;32m----> 3\u001b[0m     windowed_frames \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhanning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_len\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\n\u001b[1;32m      4\u001b[0m     sum_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_frame:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# Print frames\u001b[39;00m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 3.90 TiB for an array with shape (22050, 24292320) and data type float64"
     ]
    }
   ],
   "source": [
    "# List all the files in the Tedlium wav directory\n",
    "ted_wav_files = os.listdir(TEDLIUM_WAV_PATH)\n",
    "\n",
    "ted_data = []\n",
    "\n",
    "for file in ted_wav_files:\n",
    "    file_path = os.path.join(TEDLIUM_WAV_PATH, file)\n",
    "    audio, sample_rate_ted = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    # Retrieve the keywords belonging to this audio:\n",
    "    # [:-8] removes the last four characters (here the file extension) from the filename\n",
    "    file_stem = file[:-4]\n",
    "    # Locate the rows in the labels dataframe belonging to this recording based on the file stem\n",
    "    labels_rows = labels_df[labels_df[\"TEDLIUM_SET\"] == file_stem]\n",
    "\n",
    "    # If the audio file does not have a corresponding row in the data frame, just continue\n",
    "    if len(labels_rows) < 1:\n",
    "        continue\n",
    "        \n",
    "    print(audio)\n",
    "    # load the mswc waveforms into audio for each row and save to ted_data (which will later be used for training)\n",
    "    for index, row in labels_rows.iterrows():\n",
    "        #retrieve the keyword and file name\n",
    "        keyword = row[\"Keyword\"]\n",
    "        keyword_file_path = os.path.join(MSWC_WAV_PATH, row[\"MSWC_AudioID\"])\n",
    "        keyword_audio, sample_rate_keyword = librosa.load(keyword_file_path, res_type='kaiser_fast') \n",
    "        \n",
    "        # Get the audio length of the keyword so that we can window the data\n",
    "        keyword_len = len(keyword_audio)\n",
    "        \n",
    "        # Convert the keyword audio to normalized mfcc\n",
    "        mfcc_keyword_audio = features_extractor(keyword_audio)\n",
    "        \n",
    "        # Window the tedlium input data \n",
    "        frames, window_frames = window_split(keyword_len, 1, audio)\n",
    "        mfcc_audio = features_extractor(window_frames)\n",
    "        \n",
    "        start_time = row[\"start_time\"]\n",
    "        end_time = row[\"end_time\"]\n",
    "        # Audio, keyword audio, start_time, end_time\n",
    "        new_row = [mfcc_audio, mfcc_keyword_audio, start_time, end_time]\n",
    "        ted_data.append(new_row)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bd9d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert ted_data to a numpy array\n",
    "ted_data_np = np.asarray(ted_data)\n",
    "\n",
    "# Divide samples and labels\n",
    "X = ted_data_np[:,:2]\n",
    "y = ted_data_np[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58cc09a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62982f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model detects the keyword within one millisecond of the actual label, return true and otherwise return false\n",
    "# This way we can compute the accuracy of the model (as opposed to e.g. the error)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
