mkdir: cannot create directory ‘/disk/ted’: Permission denied
Let's use 2 GPUs!
[INFO] Exp. name : asr_example_sd0                                                                         
[INFO] Loading data... large corpus may took a while.                                                      
{'name': 'Tedlium', 'path': '/home/s1870697/MLP_Group_Project/src/Data/TEDLIUM_release-3/legacy', 'train_split': ['train'], 'dev_split': ['dev'], 'bucketing': True, 'batch_size': 2}
tedlium
['dev']
8
['train']
50
[INFO] Data spec. | Corpus = Tedlium (from /home/s1870697/MLP_Group_Project/src/Data/TEDLIUM_release-3/legacy)
[INFO]            | Train sets = ['train']	| Number of utts = 50                                           
[INFO]            | Dev sets = ['dev']	| Number of utts = 8                                                
[INFO]            | Batch size = 2		| Bucketing = True                                                     
[INFO] I/O spec.  | Audio feature = mfcc	| feature dim = 39	| Token type = character	| Vocab size = 32     
[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         
[INFO]            | VGG Extractor w/ time downsampling rate = 4 in encoder enabled.                        
[INFO]            | loc attention decoder enabled ( lambda = 1.0).                                         
[INFO] Optim.spec.| Algo. = Adadelta	| Lr = 1.0	 (Scheduler = fixed)| Scheduled sampling = False           
[INFO] Total training steps 100.0K.                                                                        
Traceback (most recent call last):
  File "/home/s1870697/MLP_Group_Project/tedlium_model/main.py", line 85, in <module>
    solver.exec()
  File "/home/s1870697/MLP_Group_Project/tedlium_model/bin/train_asr.py", line 142, in exec
    self.model(feat, feat_len, max(txt_len), tf_rate=tf_rate,
  File "/home/s1870697/miniconda3/envs/ctrlf_project/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/s1870697/miniconda3/envs/ctrlf_project/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 158, in forward
    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)
  File "/home/s1870697/miniconda3/envs/ctrlf_project/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 175, in scatter
    return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)
  File "/home/s1870697/miniconda3/envs/ctrlf_project/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py", line 44, in scatter_kwargs
    inputs = scatter(inputs, target_gpus, dim) if inputs else []
  File "/home/s1870697/miniconda3/envs/ctrlf_project/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py", line 36, in scatter
    res = scatter_map(inputs)
  File "/home/s1870697/miniconda3/envs/ctrlf_project/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py", line 23, in scatter_map
    return list(zip(*map(scatter_map, obj)))
  File "/home/s1870697/miniconda3/envs/ctrlf_project/lib/python3.9/site-packages/torch/nn/parallel/scatter_gather.py", line 19, in scatter_map
    return Scatter.apply(target_gpus, None, dim, obj)
  File "/home/s1870697/miniconda3/envs/ctrlf_project/lib/python3.9/site-packages/torch/nn/parallel/_functions.py", line 96, in forward
    outputs = comm.scatter(input, target_gpus, chunk_sizes, ctx.dim, streams)
  File "/home/s1870697/miniconda3/envs/ctrlf_project/lib/python3.9/site-packages/torch/nn/parallel/comm.py", line 189, in scatter
    return tuple(torch._C._scatter(tensor, devices, chunk_sizes, dim, streams))
RuntimeError: chunk expects at least a 1-dimensional tensor
